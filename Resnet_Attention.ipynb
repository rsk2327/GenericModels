{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EdutyPliolr5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGk_jHFBpory"
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TUCrjeCfpouc"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FW68JGMPz9gz"
   },
   "outputs": [],
   "source": [
    "class AttMap(nn.Module):\n",
    "  \n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(AttMap, self).__init__()\n",
    "        \n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.conv3 = conv1x1(planes,1)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DfxM5PjkqwHW"
   },
   "outputs": [],
   "source": [
    "class testModel(nn.Module):\n",
    "\n",
    "  def __init__(self, attention = False):\n",
    "    super(testModel, self).__init__()\n",
    "\n",
    "    self.attention = attention\n",
    "\n",
    "    self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "    self.layer1 = BasicBlock(64,64)\n",
    "    self.atten1 = AttMap(64,32)\n",
    "    self.layer2 = BasicBlock(64,64)\n",
    "    self.atten2 = AttMap(64,32)\n",
    "    self.pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "    self.fc = nn.Linear(64,10)\n",
    "\n",
    "    self.atten1Map =0\n",
    "    self.atten1Map_=0\n",
    "    self.atten2Map =0\n",
    "    self.atten2Map_=0\n",
    "\n",
    "    for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "\n",
    "    x = (F.relu(self.bn1(self.conv1(x))))\n",
    "\n",
    "    x = self.layer1(x)\n",
    "    \n",
    "    if self.attention:\n",
    "      y= self.atten1(x)\n",
    "      self.atten1Map = y\n",
    "      x = x + x*y\n",
    "      self.atten1Map_ = x\n",
    "\n",
    "      \n",
    "    x = self.layer2(x)\n",
    "\n",
    "    if self.attention:\n",
    "      y= self.atten2(x)\n",
    "      self.atten2Map = y\n",
    "      x = x + x*y\n",
    "      self.atten2Map_ = x\n",
    "\n",
    "    x = self.pooling(x)\n",
    "    x = x.view(-1, 64)\n",
    "    x = nn.Softmax()(self.fc(x))\n",
    "\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UPnm7S_iOPT_"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WRXCj6ABO_Mr"
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = testModel(attention = False).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGrsxktAD9FL"
   },
   "outputs": [],
   "source": [
    "def train(model,epochs,train_loader,optimizer,criterion):\n",
    "\n",
    "  model.train()\n",
    "  model = model.train()\n",
    "  for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "\n",
    "def test(model, test_loader):\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "      for data, target in test_loader:\n",
    "          data, target = data.to(device), target.to(device)\n",
    "          output = model(data)\n",
    "          test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "          pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "          correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "\n",
    "  print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "      test_loss, correct, len(test_loader.dataset),\n",
    "      100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model without Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "vKDiORgTOPZm",
    "outputId": "f859146e-a300-49ff-deb4-8e37673380df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosr/.conda/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.292784\n",
      "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.976549\n",
      "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.678085\n",
      "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.586987\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.518456\n",
      "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.544765\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.522075\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.495365\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.509186\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 1.518276\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 1.473954\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 1.482965\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.484640\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 1.467555\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 1.470167\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 1.486895\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.472995\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 1.482073\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.479075\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 1.479897\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.465635\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 1.476358\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.516079\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 1.467825\n"
     ]
    }
   ],
   "source": [
    "model = testModel(attention = False).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# model.train()\n",
    "train(model,4,train_loader,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "G6TfuxQlOPe0",
    "outputId": "f63e328c-f841-45d3-efd0-7ca89bb2dc95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosr/.conda/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0301, Accuracy: 9678/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GR5QOY4S9yUC"
   },
   "source": [
    "#### Model with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U5YHeOK_OPpH"
   },
   "outputs": [],
   "source": [
    "model = testModel(attention = True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "8bnhaBZTOP2M",
    "outputId": "754da88b-8362-45a6-9719-3f031e2cda55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.639761\n",
      "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.495242\n",
      "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.487287\n",
      "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.486227\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.531934\n",
      "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.471654\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.503177\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.465182\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.479340\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 1.485402\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 1.478961\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 1.494953\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.486776\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 1.483708\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 1.466293\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 1.501932\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.478698\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 1.470734\n"
     ]
    }
   ],
   "source": [
    "train(model,3,train_loader,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "M1ntRhlQOP-D",
    "outputId": "0c1edf23-6766-4910-a968-510104b1197f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0299, Accuracy: 9754/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BdltnlSsTH-e"
   },
   "source": [
    "#### Assigning forward hook for map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGdsATSyOQBV"
   },
   "outputs": [],
   "source": [
    "maskVal = 0\n",
    "\n",
    "def copyData(m, inp, out):\n",
    "  global maskVal\n",
    "  out1 = out.detach().cpu().numpy()\n",
    "  maskVal = out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vd8ClH_MOQGo"
   },
   "outputs": [],
   "source": [
    "#hook to return map for attn1\n",
    "mapHook = list(list(model.children())[3].children())[5].register_forward_hook(copyData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPVFb-OEOQEp"
   },
   "outputs": [],
   "source": [
    "testData = datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rQtOoAo2OP8L",
    "outputId": "eef38d62-2083-4dfe-8825-44f7648d9405"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "i = 9\n",
    "sample = testData[i][0]\n",
    "\n",
    "\n",
    "out = model(sample.unsqueeze(0).cuda())\n",
    "\n",
    "maskVal = nn.Sigmoid()(torch.Tensor(maskVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "6LZv5wzcOPxA",
    "outputId": "6174287e-14b9-46f9-90a1-0882f9cafe03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f14e1fc2c88>"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIqGwi0RCYReJhMIuEgmFXSQSCrtIJP4fmDlG7wVRuVoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(maskVal[0,0,:,:].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "ciIBVAtpOPsN",
    "outputId": "3da25bf0-7d63-4377-8eee-e1f2f6f93728"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f14e1f9af28>"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH98DZWntI7c0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "6qEtwhE4OPnL",
    "outputId": "b1113a4f-7768-46a0-90d8-5d619e50bfe2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f14e1f7a550>"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIqGwi0RCYReJhMIuEgmFXSQSCrtIJP4fmDlG7wVRuVoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(model.atten1Map[0,0,:,:].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "NIU1uslWOPh8",
    "outputId": "29b1bb9d-6a8e-4df7-96f3-ba390ab542c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f14e1ed8278>"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(model.atten1Map_[0,0,:,:].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Altered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))\n",
    "\n",
    "\n",
    "trainData = datasets.MNIST('../data', train=True, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zek0hXn2jfUc"
   },
   "outputs": [],
   "source": [
    "def getAlteredSample(x):\n",
    "\n",
    "  blockSize = np.random.randint(20,60)\n",
    "\n",
    "  block = np.array(Image.fromarray(x[0].numpy()).resize((blockSize,blockSize)))\n",
    "\n",
    "  imgSize = (100,100)\n",
    "  blockSize = block.shape\n",
    "\n",
    "  img = np.ones(imgSize)*-0.4242\n",
    "\n",
    "  xpos = np.random.randint(0,imgSize[0]-blockSize[0]-1)\n",
    "  ypos = np.random.randint(0,imgSize[1]-blockSize[1]-1)\n",
    "\n",
    "  img[xpos : xpos + blockSize[0], ypos : ypos + blockSize[1]] = block\n",
    "\n",
    "  return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlteredMNIST(torch.utils.data.Dataset):\n",
    " \n",
    "\n",
    "    def __init__(self,dataset):\n",
    "\n",
    "        self.data = dataset\n",
    "     \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample,label = self.data[idx]\n",
    "        sample = getAlteredSample(sample)\n",
    "        \n",
    "        sample = transforms.ToTensor()(sample).float()\n",
    "\n",
    "        \n",
    "        return sample,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "XEveg5u0OPXl",
    "outputId": "2424b40e-cb21-4a03-ce46-05ae7c84eca6"
   },
   "outputs": [],
   "source": [
    "trainAlterData = AlteredMNIST(trainData)\n",
    "testAlterData = AlteredMNIST(testData)\n",
    "\n",
    "batch_size = 80\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        trainAlterData,\n",
    "        batch_size=batch_size, shuffle=True )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        testAlterData,\n",
    "        batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = testModel(attention = False).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosr/.conda/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.290374\n",
      "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.464105\n",
      "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.462110\n",
      "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.461576\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.461431\n",
      "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.461382\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.461281\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.461231\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-2517ae042fc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-fed46043c54e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs, train_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model,4,train_loader,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosr/.conda/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0473, Accuracy: 974/10000 (10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = testModel(attention = False).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosr/.conda/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.301062\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 2.110584\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 1.940921\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 1.804793\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.839396\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.857726\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.765292\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.736982\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.720395\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 1.776332\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.596818\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.667929\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.568069\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.586730\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.581098\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.644857\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.624745\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1.540407\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.507859\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 1.524424\n"
     ]
    }
   ],
   "source": [
    "train(model,5,train_loader,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosr/.conda/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0293, Accuracy: 1142/10000 (11%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosr/.conda/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0293, Accuracy: 6937/60000 (12%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import ResNet, BasicBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistResNet(ResNet):\n",
    "    def __init__(self):\n",
    "        super(MnistResNet, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=10)\n",
    "        self.conv1 = torch.nn.Conv2d(1, 64, \n",
    "            kernel_size=(7, 7), \n",
    "            stride=(2, 2), \n",
    "            padding=(3, 3), bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.softmax(\n",
    "            super(MnistResNet, self).forward(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistResNet()\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.308944\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 1.669950\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 1.556081\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 1.552795\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.518126\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.605050\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.507868\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.523019\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.541521\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 1.487757\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.587193\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.489241\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.526473\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.545880\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.499511\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.528147\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.504833\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1.498378\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.488059\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 1.516719\n"
     ]
    }
   ],
   "source": [
    "train(model,5,train_loader,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 9561/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0189, Accuracy: 56798/60000 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "kMtgo40wOPPt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc0dcbb9f28>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "hidden": true,
    "id": "sU08221fOPNq",
    "outputId": "d521638a-18aa-4636-e2fb-0cc5079b4845"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f14e1c2f550>"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "hidden": true,
    "id": "JzkL4WjMi7WL",
    "outputId": "b7ea6858-88e6-48b2-efda-f72a81d9ed9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.0340,  0.2886,  1.3196,\n",
       "          2.1342,  2.1087,  0.7850,  0.0467, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242,  0.1486,  1.5105,  2.5542,  2.8088,  2.8088,\n",
       "          2.8088,  2.8088,  2.8088,  2.7578,  2.2614,  1.4978, -0.3478, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242,  0.1613,  1.5232,  2.6306,  2.8088,  2.8088,  2.4651,  1.6887,\n",
       "          1.2686,  2.7706,  2.1214,  2.8088,  2.4906,  2.4396,  0.8995, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          1.5232,  2.5542,  2.8088,  2.8088,  1.9560,  1.3832, -0.3224, -0.4242,\n",
       "         -0.4242,  2.0069,  0.0849,  2.0960,  2.7069,  2.4142,  2.7960, -0.1569,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3224,  1.1795,\n",
       "          2.7960,  2.8088,  2.5415,  1.2050, -0.2842, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242,  2.2487,  0.1231,  0.4668,  2.8088,  2.8088,  2.8088, -0.1569,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.4922,  2.6687,\n",
       "          2.8088,  2.4778,  0.2631, -0.4242, -0.4242, -0.4242, -0.4242, -0.3860,\n",
       "         -0.0169,  1.0523,  2.4396,  2.6560,  2.8088,  2.8215,  1.6378, -0.3606,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.5304,  2.6306,\n",
       "          2.8088,  2.4142,  0.9632,  1.3323,  1.8414,  1.8414,  1.7269,  2.2487,\n",
       "          2.7706,  2.5160,  2.8088,  2.8088,  2.8088,  2.5287,  0.0595, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3097,  1.8032,\n",
       "          2.6815,  2.7960,  2.8215,  2.8088,  2.8088,  2.7706,  2.8088,  2.8088,\n",
       "          2.8088,  2.8088,  2.8088,  2.7833,  1.7523, -0.1060, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.2206,  1.3068,  2.0578,  1.8160,  1.4341,  1.5232,  2.1214,  2.8088,\n",
       "          2.8088,  2.8088,  2.8088,  1.4850, -0.2206, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  1.6378,  2.8088,\n",
       "          2.8088,  2.6433,  0.8359, -0.3860, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  1.0777,  2.7578,  2.8088,\n",
       "          2.8088,  0.7213, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242,  0.8486,  2.6560,  2.8088,  2.8088,\n",
       "          2.2614, -0.3351, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242,  0.2631,  2.6433,  2.8088,  2.8088,  2.6560,\n",
       "          0.3268, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242,  1.2432,  2.8088,  2.8088,  2.6815,  0.3904,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.2587,  2.7451,  2.8088,  2.8088,  1.5105, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.2715,  2.4778,  2.8088,  2.8088,  2.2233, -0.3224, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242,  0.5686,  2.8215,  2.8088,  2.8088,  0.4159, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242,  2.2360,  2.8088,  2.8088,  1.3196, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242,  2.4651,  2.8215,  2.5415, -0.1060, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242,  1.0141,  2.8215,  0.9504, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242]])"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "WiPXCXD5i7TS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "unToozn5i7Pj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "c7NADxOqi7LV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "yNsNzbs5qMKC"
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "O7eTnWu2qMM6"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "Gtuq8bmBuYwd"
   },
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "\n",
    "\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "WaGcuqWIuYzd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "b5kh6ws5uY2S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "VGA5dptNuY46"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "buzcQtapuY7e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "p0SiKDHmuY-D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "COW5unG4uZA3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "MeqhBBpGuZDj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "cZ7chxTsuZF9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "VccSv2OxuZJE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "RjiEaDC8qMPF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "hidden": true,
    "id": "ptGcndyfpNP7",
    "outputId": "5494be94-fa5b-4671-c7ad-9a152123e148"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5f6876f143f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m train_loader = torch.utils.data.DataLoader(\n\u001b[0;32m----> 5\u001b[0;31m         datasets.MNIST('../data', train=True, download=True,\n\u001b[0m\u001b[1;32m      6\u001b[0m                        transform=transforms.Compose([\n\u001b[1;32m      7\u001b[0m                            \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 50\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "Nd_fmLYIpNSV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "YZXqRksfpNUQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "hidden": true,
    "id": "yu7R8_WMoq4U",
    "outputId": "370f5ce7-180c-415d-d778-d5f1ed22cdd2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-82b1960216b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "ocWPduGUo8YV"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.ConvTranspose2d(3,10,1)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "A5FBvVNADJPs"
   },
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "NooR0FjEDM9H"
   },
   "outputs": [],
   "source": [
    "a = torch.rand((10,3,10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "JbPHFp4pE1_a"
   },
   "outputs": [],
   "source": [
    "out = net(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "Mi0ztx3uTMSJ"
   },
   "outputs": [],
   "source": [
    "w = iter(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "G3FiQOHkE2EC"
   },
   "outputs": [],
   "source": [
    "a = next(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "hidden": true,
    "id": "QznMj-fqE2CX",
    "outputId": "09663556-03cd-4a11-cf71-ac112c7e33b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "hidden": true,
    "id": "FDzD_4hdDQlq",
    "outputId": "13c559ee-dffc-417b-d985-003d2db7a85b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.1243]],\n",
      "\n",
      "         [[-0.5421]],\n",
      "\n",
      "         [[ 0.3279]]],\n",
      "\n",
      "\n",
      "        [[[-0.1762]],\n",
      "\n",
      "         [[-0.1829]],\n",
      "\n",
      "         [[-0.3538]]],\n",
      "\n",
      "\n",
      "        [[[-0.2390]],\n",
      "\n",
      "         [[-0.5210]],\n",
      "\n",
      "         [[-0.1505]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4943]],\n",
      "\n",
      "         [[ 0.3299]],\n",
      "\n",
      "         [[ 0.2782]]],\n",
      "\n",
      "\n",
      "        [[[-0.3986]],\n",
      "\n",
      "         [[ 0.2170]],\n",
      "\n",
      "         [[ 0.5023]]],\n",
      "\n",
      "\n",
      "        [[[-0.1039]],\n",
      "\n",
      "         [[-0.5375]],\n",
      "\n",
      "         [[ 0.0492]]],\n",
      "\n",
      "\n",
      "        [[[-0.2158]],\n",
      "\n",
      "         [[-0.0592]],\n",
      "\n",
      "         [[-0.5070]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5075]],\n",
      "\n",
      "         [[-0.0797]],\n",
      "\n",
      "         [[ 0.0920]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0289]],\n",
      "\n",
      "         [[ 0.3521]],\n",
      "\n",
      "         [[-0.4791]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0140]],\n",
      "\n",
      "         [[ 0.4927]],\n",
      "\n",
      "         [[-0.2458]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.5756, -0.0097, -0.3002,  0.3459,  0.1772, -0.4801,  0.3421,  0.0394,\n",
      "         0.1498,  0.4048], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in net.parameters():\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "hidden": true,
    "id": "O_45Se7aDTmQ",
    "outputId": "4a75716e-4768-4a80-d3a8-d1fb3e8db592"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([np.prod(p.size()) for p in net.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "hidden": true,
    "id": "1mL_lFTMDrlb",
    "outputId": "c5cac298-3293-4cc3-8fa5-00f3ab19aabe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of Net(\n",
       "  (conv1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "hidden": true,
    "id": "w3VnAat5DydD",
    "outputId": "36d54838-b4bd-4ad7-c54e-71d33e51e782"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ddbf25bee087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Net' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "for i in net.modules():\n",
    "  print(i.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "p2BlovBkEEjo"
   },
   "outputs": [],
   "source": [
    "w = iter(net.modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "zj0PhptoELZh"
   },
   "outputs": [],
   "source": [
    "q = next(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "hidden": true,
    "id": "sfsGfjEgEMXx",
    "outputId": "45428a90-1a65-4f45-8577-2c20ea070203"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Net(\n",
       "  (conv1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")>"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "lLmMluU6ENvl"
   },
   "outputs": [],
   "source": [
    "q = iter(net.bn1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "hidden": true,
    "id": "PROqLz_qFh10",
    "outputId": "1319e542-4888-4340-b097-5fa5fc87bef5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "hidden": true,
    "id": "pCyQj249Fm1T",
    "outputId": "75083b23-1df1-4fea-f467-614b1fd37d2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "hidden": true,
    "id": "p-WSXas2Fogp",
    "outputId": "7211fae9-ce7f-46a0-f6ea-3e86259ba822"
   },
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-e98e88d97d37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "f4hFpfOhFpfh"
   },
   "outputs": [],
   "source": [
    "a = torch.rand(10,1,5,5)\n",
    "b = torch.rand(10,6,5,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "qpMDxICPF3E0"
   },
   "outputs": [],
   "source": [
    "a = np.array(list(range(250)))\n",
    "b = np.array(list(range(150))*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "_NMHbvnk6tpW"
   },
   "outputs": [],
   "source": [
    "a = np.reshape(a,(10,1,5,5))\n",
    "b = np.reshape(b,(10,6,5,5))\n",
    "\n",
    "a = torch.Tensor(a)\n",
    "b = torch.Tensor(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "TOQIkof86tsc"
   },
   "outputs": [],
   "source": [
    "c = a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "hidden": true,
    "id": "824vimS86tm5",
    "outputId": "82e8db4b-93c5-4f5b-cc6d-eba8d43f2169"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6, 5, 5])"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "hidden": true,
    "id": "jnkkGatO7PIl",
    "outputId": "37fef1c7-f5b0-45b3-a133-8b92141b4a53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25., 26., 27., 28., 29.],\n",
       "        [30., 31., 32., 33., 34.],\n",
       "        [35., 36., 37., 38., 39.],\n",
       "        [40., 41., 42., 43., 44.],\n",
       "        [45., 46., 47., 48., 49.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testa = a[1,0,:,:]\n",
    "testa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "hidden": true,
    "id": "7euL_bWQ7PL2",
    "outputId": "b04f6310-2b1c-40b9-8816-72fb16c7f366"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50., 51., 52., 53., 54.],\n",
       "        [55., 56., 57., 58., 59.],\n",
       "        [60., 61., 62., 63., 64.],\n",
       "        [65., 66., 67., 68., 69.],\n",
       "        [70., 71., 72., 73., 74.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testb = b[1,2,:,:]\n",
    "testb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "hidden": true,
    "id": "eU9xj0Vd7PGN",
    "outputId": "691642b4-403e-4765-e873-9a37eb4e3637"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1250., 1326., 1404., 1484., 1566.],\n",
       "        [1650., 1736., 1824., 1914., 2006.],\n",
       "        [2100., 2196., 2294., 2394., 2496.],\n",
       "        [2600., 2706., 2814., 2924., 3036.],\n",
       "        [3150., 3266., 3384., 3504., 3626.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testa*testb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "hidden": true,
    "id": "osOeKX7I7PDq",
    "outputId": "7ea7fa11-bf59-4e81-abb4-4c04e7032085"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1250., 1326., 1404., 1484., 1566.],\n",
       "        [1650., 1736., 1824., 1914., 2006.],\n",
       "        [2100., 2196., 2294., 2394., 2496.],\n",
       "        [2600., 2706., 2814., 2924., 3036.],\n",
       "        [3150., 3266., 3384., 3504., 3626.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[1,2,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "DAYgvKZD9QT3"
   },
   "source": [
    "## FB Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "DRziZe4c_R5c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "w03SzBVW9TLj"
   },
   "outputs": [],
   "source": [
    "dates = ['2012-10-01','2012-10-02','2012-10-03','2012-10-04','2012-10-05']\n",
    "\n",
    "studentIds = list(range(1,21))\n",
    "\n",
    "attendData = []\n",
    "\n",
    "for i in dates:\n",
    "  for j in studentIds:\n",
    "    attendData.append([i,j,random.randint(0,1)])\n",
    "\n",
    "attendDf = pd.DataFrame(attendData)\n",
    "attendDf.columns = ['date','studentID','attend']\n",
    "\n",
    "attendDf.date = pd.to_datetime(attendDf.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "hidden": true,
    "id": "8Fb-x8pw_2yB",
    "outputId": "5eb83e6a-0993-493a-d0eb-650540d46047"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>studentID</th>\n",
       "      <th>attend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  studentID  attend\n",
       "0 2012-10-01          1       1\n",
       "1 2012-10-01          2       1\n",
       "2 2012-10-01          3       0\n",
       "3 2012-10-01          4       0\n",
       "4 2012-10-01          5       1"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "g2W2zwpV_4Vl"
   },
   "outputs": [],
   "source": [
    "studentData = []\n",
    "\n",
    "for i in studentIds:\n",
    "  studentData.append([i, random.randint(1,3)])\n",
    "\n",
    "studentDf = pd.DataFrame(studentData)\n",
    "studentDf.columns = ['studentID','grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "HP5kOp9Q_8FX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "hidden": true,
    "id": "na4AxH6QAYVw",
    "outputId": "50d10d0e-c912-45e4-d2f4-16146e5d60ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studentID</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   studentID  grade\n",
       "0          1      3\n",
       "1          2      1\n",
       "2          3      2\n",
       "3          4      1\n",
       "4          5      3"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studentDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "wJitkxj_C39J"
   },
   "outputs": [],
   "source": [
    "df = pd.merge(attendDf, studentDf, on='studentID',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "hidden": true,
    "id": "hQS8LCiNDc_n",
    "outputId": "0f487ecc-edc5-4298-ef0f-af8752c9f8e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>studentID</th>\n",
       "      <th>attend</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  studentID  attend  grade\n",
       "0 2012-10-01          1       1      3\n",
       "1 2012-10-01          2       1      1\n",
       "2 2012-10-01          3       0      2\n",
       "3 2012-10-01          4       0      1\n",
       "4 2012-10-01          5       1      3"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "OfrQnTn8DtFF"
   },
   "outputs": [],
   "source": [
    "d = df.groupby(['date','grade'])['attend'].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "sVFuOnIVGMCo"
   },
   "outputs": [],
   "source": [
    "d = d.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "cmJrHT92HNIh"
   },
   "outputs": [],
   "source": [
    "d['lastAttend'] = d.groupby('grade')['attend'].shift(1)\n",
    "d['attendDiff'] = d.lastAttend - d.attend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "hidden": true,
    "id": "BvcCQCYmLQ4e",
    "outputId": "8a7a56c3-c043-4484-a89b-0d354a80ccd2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>grade</th>\n",
       "      <th>attend</th>\n",
       "      <th>lastAttend</th>\n",
       "      <th>attendDiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  grade  attend  lastAttend  attendDiff\n",
       "0 2012-10-01      1   0.625         NaN         NaN\n",
       "1 2012-10-01      2   0.750         NaN         NaN\n",
       "2 2012-10-01      3   0.500         NaN         NaN\n",
       "3 2012-10-02      1   0.750       0.625      -0.125\n",
       "4 2012-10-02      2   0.500       0.750       0.250"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "mkNzHyzFGTnA"
   },
   "outputs": [],
   "source": [
    "w = d[d.grade==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "hidden": true,
    "id": "23iZcKbPHSHW",
    "outputId": "47ff3988-1834-4390-8bfa-d9a554198bb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "3     0.625\n",
       "6     0.750\n",
       "9     0.375\n",
       "12    0.625\n",
       "Name: attend, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.attend.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "cJrTYxwvI5Au"
   },
   "outputs": [],
   "source": [
    "def getShift(x):\n",
    "\n",
    "  x = x.sort_values('date')\n",
    "  x['LastAttend'] = x.attend.shift(1)\n",
    "  x['attendDiff'] = x.attend - x.LastAttend\n",
    "\n",
    "  return x[['date','attendDiff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "3GScFFMgIfQK"
   },
   "outputs": [],
   "source": [
    "out = d.groupby('grade').apply(getShift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "vLHIqOgWJQGa"
   },
   "outputs": [],
   "source": [
    "\n",
    "out = out.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "hidden": true,
    "id": "peIawmOUJVWq",
    "outputId": "19d0e3ee-90e7-4fee-85a7-28af22c33157"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>level_1</th>\n",
       "      <th>date</th>\n",
       "      <th>attendDiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2012-10-03</td>\n",
       "      <td>-0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2012-10-03</td>\n",
       "      <td>-0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-10-03</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    grade  level_1       date  attendDiff\n",
       "2       1        6 2012-10-03      -0.375\n",
       "7       2        7 2012-10-03      -0.250\n",
       "12      3        8 2012-10-03      -0.500"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "out[out.date == pd.to_datetime('2012-10-03')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "hidden": true,
    "id": "YBlXcxnsJkrW",
    "outputId": "1e949487-2c0e-4d6f-b572-aa100b84d29f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>grade</th>\n",
       "      <th>attend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012-10-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012-10-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012-10-03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012-10-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012-10-04</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012-10-04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  grade  attend\n",
       "0  2012-10-01      1   0.625\n",
       "1  2012-10-01      2   0.750\n",
       "2  2012-10-01      3   0.500\n",
       "3  2012-10-02      1   0.750\n",
       "4  2012-10-02      2   0.500\n",
       "5  2012-10-02      3   0.875\n",
       "6  2012-10-03      1   0.375\n",
       "7  2012-10-03      2   0.250\n",
       "8  2012-10-03      3   0.375\n",
       "9  2012-10-04      1   0.625\n",
       "10 2012-10-04      2   1.000\n",
       "11 2012-10-04      3   0.250\n",
       "12 2012-10-05      1   0.750\n",
       "13 2012-10-05      2   0.750\n",
       "14 2012-10-05      3   0.875"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "XMWkE_b2Jx1S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "DAYgvKZD9QT3"
   ],
   "name": "Resnet_Attention",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
